"""
This file defines the WindowGenerator model.
"""

from typing import Union, Tuple, List, Optional, Any
import pandas as pd
import numpy as np

import tensorflow as tf
from tensorflow.keras.backend import floatx

from .. import AutopycoinBaseClass


STRATEGIES = ["one_shot", "auto_regressive"]


class WindowGenerator(AutopycoinBaseClass):
    """
    Transform a time series dataset into an usable format.
    It can be either a pandas dataframe, tensorflow tensor or numpy array by calling
    the respective method `from_dataframe` or `from_tensor`.

    Parameters
    ----------
    input_width : int
        The number of historical time steps to use during the forecasting.
    label_width : int
        the number of time steps to forecast.
    shift : int
        Compute the shift between input time steps (`input_width`) and
        labels time steps (`label_width`).
        Hence if `label_width` is higher than `shift` label input and label datasets
        will have some indentical values.
    valid_size : int
        The number of examples in the validation set.
    test_size : int
        The number of examples in the test set.
    strategy : str
        "one_shot" or "auto_regressive". It defines the datasets shape.
    batch_size : int, `Optional`
        The number of examples per batch. If None, then all examples are stacked in one batch.
        Default to None.
    preprocessing : callable or None, `Optional`
        Preprocessing function to use on the data.
        This function will to take input of shape ((inputs, known, date_inputs, date_labels), labels).
        Default to None.

    Attributes
    ----------
    input_width : int
    label_width : int
    shift : int
    valid_size : int
    test_size : int
    strategy : str
    batch_size : int or None
    train_data : Dataframe
    valid_data : Dataframe
    test_data : Dataframe
    train : `dataset`
    valid : `dataset`
    test : `dataset`
    data : DataFrame

    Notes
    -----
    The output shape corresponds to each dataset shape defined by the train, valid, test or production properties.
    *Output shape*:
    Tuple of shape ((inputs, known, date_inputs, date_labels), labels)

    with inputs:
            The input tensor of shape (batch_size, input_width, input_columns) or (batch_size, input_width * input_columns)
            depending of the strategy used.
    with known:
            The known tensor of shape (batch_size, input_width, known_columns) or (batch_size, input_width * known_columns)
            depending of the strategy used.
            Variables whose values are known
            in advance or estimated. For example: time dates or temperatures.
    with date_inputs:
            Dates of shape (batch_size, input_width) associated to the Input tensor.
            Default to a tensor generated by `tf.range`.
    with date_labels:
            Default to a tensor generated by `tf.range`.
    with labels:
            The Output variables of shape (batch_size, label_width, label_columns) or (batch_size, label_width * label_columns)
            depending of the strategy used.

    respectively `auto_regressive` or `one_shot`.

    Examples
    --------
    >>> import pandas as pd
    >>> from autopycoin.data import random_ts
    >>> from autopycoin.dataset import WindowGenerator
    >>> data = random_ts(n_steps=100,
    ...                  trend_degree=2,
    ...                  periods=[10],
    ...                  fourier_orders=[10],
    ...                  trend_mean=0,
    ...                  trend_std=1,
    ...                  seasonality_mean=0,
    ...                  seasonality_std=1,
    ...                  batch_size=1,
    ...                  n_variables=1,
    ...                  noise=True,
    ...                  seed=42)
    >>> data = pd.DataFrame(data[0], columns=['values'])
    >>> w_oneshot = WindowGenerator(input_width=3,
    ...                             label_width=2,
    ...                             shift=10,
    ...                             valid_size=2,
    ...                             test_size=3,
    ...                             strategy='one_shot',
    ...                             batch_size=None,
    ...                             preprocessing=None)
    >>> w_oneshot = w_oneshot.from_dataframe(data,
    ...     input_columns=['values'],
    ...     label_columns=['values'],
    ...     known_columns=[],
    ...     date_columns=[])
    >>> w_oneshot.train
    <PrefetchDataset element_spec=((TensorSpec(shape=(None, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 0), dtype=tf.float32, name=None), TensorSpec(shape=(None, 3), dtype=tf.string, name=None), TensorSpec(shape=(None, 2), dtype=tf.string, name=None)), TensorSpec(shape=(None, 2), dtype=tf.float32, name=None))>
    """

    def __init__(
        self,
        input_width: int,
        label_width: int,
        shift: int,
        valid_size: int,
        test_size: int,
        strategy: str,
        batch_size: Optional[int] = None,
        preprocessing: Union[tf.keras.layers.Layer, None] = None,
    ): # pylint: disable=dangerous-default-value

        self._input_width = input_width
        self._label_width = label_width
        self._shift = shift

        self._valid_size = valid_size
        self._test_size = test_size

        self.batch_size = batch_size
        self.strategy = strategy

        # We separate init functions in order to perfom validation.
        self._compute_window_parameters()

        # Preprocessing layers
        self._preprocessing = preprocessing
        self._initialized = False

    def _compute_window_parameters(self) -> None:
        """Calculate the window parameters."""

        self._total_window_size = self.input_width + self.shift

        self._input_slice = slice(0, self.input_width)
        self._input_indices = np.arange(self._total_window_size)[self._input_slice]

        self._label_start = self._total_window_size - self.label_width
        self._label_slice = slice(self._label_start, None)
        self._label_indices = np.arange(self._total_window_size)[self._label_slice]

    def from_dataframe(
        self,
        data: pd.DataFrame,
        input_columns: List[str],
        label_columns: List[str],
        known_columns: List[str] = [],
        date_columns: List[str] = []):
        """
        Feed `WindowGenerator` with a dataframe. This method
        has to be called before using `train,, `test` or `valid` methods
        as it initializes the data.

        Parameters
        ----------
        data : `DataFrame of shape (timesteps, variables)`
            The time series dataframe on which train, valid and test datasets are built.
        input_columns : list[str]
            The input column names. Variables used to forecast target values.
        label_columns : list[str]
            The label column names. Target variables to forecast.
        known_columns : list[str], `Optional`
            The known column names, default to [].
            Those variables that we know exact or strong estimated values which happen during target period.
            Example: Dates or temperatures.
        date_columns : list[str], `Optional`
            The date column names. Dates associated to each steps, default to [].
            Date columns will be cast to string and join by
            '-' delimiter to be used as xticks in plot function.
            If [] is provided then the date column is "date" if it exists.
            Else takes the index as date column.

        Returns
        -------
        self : `WindowGenerator`
            return the instance.
        """

        self._initialized = True

        # Avoid replacing original dataframe
        data = data.copy()
        # Default creation of a date column
        if not date_columns and 'date' in data.columns:
            date_columns = ["date"]
        elif not date_columns:
            data, date_columns = self._date_columns_handler(data)

        # Converting dataframe into array
        self._data_columns = data.columns
        self._data = data.values

        # Get index for each columns
        try:
            self._input_columns = [self._data_columns.get_loc(col) for col in input_columns]
            self._label_columns = [self._data_columns.get_loc(col) for col in label_columns]
            self._known_columns = [self._data_columns.get_loc(col) for col in known_columns]
            self._date_columns = [self._data_columns.get_loc(col) for col in date_columns]
        except KeyError as error:
            raise KeyError(
                f"""Columns are not found inside data, got input_columns: {input_columns},
                label_columns: {label_columns}, known_columns: {known_columns} and date_columns: {date_columns}.
                Expected {self._data_columns}."""
                ) from error

        self._compute_train_valid_test_split()

        return self

    def _date_columns_handler(self, data: pd.DataFrame) -> Tuple[pd.DataFrame, list]:
        """Handle the case data has no date columns."""
        date_columns = data.index.names if data.index.names[0] else ['date']
        # We have to rearrange columns
        columns = data.columns
        data = data.reset_index()
        if date_columns == ['date']:
            data = data.rename(columns={'index':"date"})
        return data[columns.tolist() + date_columns], date_columns

    def from_array(
        self,
        data: Union[np.ndarray, tf.Tensor],
        input_columns: List[Union[slice, int]],
        label_columns: List[Union[slice, int]],
        known_columns: List[Union[slice, int]] = [],
        date_columns: List[Union[slice, int]] = []):
        """
        Feed `WindowGenerator` with a tensor or an array. This method
        has to be called before using `train,, `test` or `valid` methods
        as it initializes the data.

        Parameters
        ----------
        data : array or `Tensor of shape (timesteps, variables) or (timesteps, variables, batch)`
            The time series array on which train, valid and test datasets are built.
        input_columns : list[int or slice]
            The input column index. Variables used to forecast target values.
        label_columns : list[int or slice]
            The label column index. Target variables to forecast.
        known_columns : list[int or slice], `Optional`
            The known column index, default to [].
            Those variables that we know exact or strong estimated values which happen during target period.
            Example: Dates or temperatures.
        date_columns : list[int or slice], `Optional`
            The date column index. Dates associated to each steps, default to [].
            Date columns will be cast to string and join by
            '-' delimiter to be used as xticks in plot function.
            If [] is provided then a last .

        Returns
        -------
        self : `WindowGenerator`
            return the instance.
        """

        self._initialized = True
        data = np.array(data)

        # Default creation of a date column
        if not date_columns:
            # Last not -1
            date_columns = [data.shape[1]]
            data = np.concatenate(
                (data,
                np.arange(len(data)).reshape(-1, 1)),
                axis=1
            )

        # Converting data into array
        self._data = data
        self._data_columns = None # Used in `production`

        self._input_columns = input_columns
        self._label_columns = label_columns
        self._known_columns = known_columns
        self._date_columns = date_columns

        self._compute_train_valid_test_split()

        return self

    def _compute_train_valid_test_split(
        self,
    ) -> None:
        """Split the data into train, valid and test array."""

        self._test_start = self.data.shape[0] - bool(self.test_size) * (
            self._total_window_size + self.test_size - 1
        )
        self._valid_start = self._test_start + bool(self.test_size) * self.input_width - bool(self.valid_size) * (
            self._total_window_size + self.valid_size - 1
        )

        self._train_data = self.data[
            : (self._valid_start + self.input_width)
        ]

        self._valid_data = self.data[
            self._valid_start : (
                self._test_start + self.input_width * bool(self.valid_size)
            )
        ]

        self._test_data = self.data[self._test_start :]

    def _make_dataset(
        self,
        data: Union[pd.DataFrame, np.ndarray, tf.Tensor],
        batch_size: Optional[int]=None,
    ) -> tf.data.Dataset:
        """
        Compute the tensorflow dataset object.

        Parameters
        ----------
        data : `dataframe`, array or `tensor of shape (timestep, variables)`
            The time series dataset.
        batch_size : int
            Set up the batch size a.k.a the number of examples per batch.

        Returns
        -------
        ds : `PrefetchDataset`
            The dataset that can be used in keras model.
        """

        if batch_size is None:
            batch_size = len(data)

        data = data.astype(floatx())

        dataset = tf.keras.preprocessing.timeseries_dataset_from_array(
            data=data,
            targets=None,
            sequence_length=self._total_window_size,
            sequence_stride=1,
            shuffle=False,
            batch_size=batch_size,
        )

        dataset = dataset.map(self._split_window, num_parallel_calls=tf.data.AUTOTUNE)

        if self._preprocessing is not None:
            dataset = dataset.map(
                self._preprocessing, num_parallel_calls=tf.data.AUTOTUNE
            )

        return dataset.prefetch(tf.data.experimental.AUTOTUNE)

    def _split_window(self, features: tf.Tensor) -> Tuple[tf.Tensor]:
        """
        Compute the window split.

        Parameters
        ----------
        features : `tensor of shape (Batch_size, timestep, variables)`
            The windows defined by `timeseries_dataset_from_array`.

        Returns
        -------
        inputs : `Tensor`
            The input tensor of shape (batch_size, input_width, input_columns) or (batch_size, input_width * input_columns)
            depending of the strategy used.
        known : `Tensor`
            The known tensor of shape (batch_size, input_width, known_columns) or (batch_size, input_width * known_columns)
            depending of the strategy used.
            Variables whose values are known
            in advance or estimated. For example: time dates or temperatures.
        date_inputs : `Tensor`
            Input dates of shape (batch_size, input_width).
            Default to a tensor generated by `tf.range`.
        date_labels : `Tensor`
            label dates of shape (batch_size, label_width).
            Default to a tensor generated by `tf.range`.
        labels : `Tensor`
            The Output variables of shape (batch_size, label_width, label_columns) or (batch_size, label_width * label_columns)
            depending of the strategy used.
        """
        # We can't use self.batch_size because the last batch could be truncated
        batch_size = tf.shape(features)[0]

        # Workout Date
        date = tf.stack(
            [features[:, :, indice] for indice in self.date_columns],
            axis=-1,
        )

        date.set_shape([None, self._total_window_size, None])
        date = tf.cast(date, tf.int32)
        date = tf.strings.as_string(date)
        date = tf.strings.reduce_join(date, separator="-", axis=-1, keepdims=True)

        date_inputs = date[:, self._input_slice]
        date_labels = date[:, self._label_slice]

        # Workout Known inputs
        if self.known_columns:
            known = tf.stack(
                [
                    features[:, self._label_slice, indice]
                    for indice in self.known_columns
                ],
                axis=-1,
            )
            known.set_shape([None, self.label_width, None])
        else:
            known = tf.repeat(
                tf.constant([[]]), repeats=batch_size, axis=0
            )  # Repeat to fit with batch
            known.set_shape(shape=(None, 0))

        # Workout inputs and labels
        inputs = features[:, self._input_slice, :]
        labels = features[:, self._label_slice, :]

        inputs = tf.stack(
            [inputs[:, :, indice] for indice in self.input_columns],
            axis=-1,
        )
        labels = tf.stack(
            [labels[:, :, indice] for indice in self.label_columns],
            axis=-1,
        )

        inputs.set_shape([None, self.input_width, len(self.input_columns)])
        labels.set_shape([None, self.label_width, len(self.label_columns)])

        # TODO: transform this `if` into class strategy
        if self.strategy == "one_shot":
            inputs = tf.reshape(
                inputs, shape=(-1, self.input_width * len(self.input_columns))
            )
            labels = tf.reshape(
                labels, shape=(-1, self.label_width * len(self.label_columns))
            )
            known = tf.reshape(
                known, shape=(-1, self.input_width * len(self.known_columns))
            )
            date_inputs = tf.reshape(
                date_inputs, shape=(-1, self.input_width)
            )
            date_labels = tf.reshape(
                date_labels, shape=(-1, self.label_width)
            )

        return (inputs, known, date_inputs, date_labels), labels

    def production(
        self, data: Union[pd.DataFrame, np.array, tf.Tensor], batch_size: Optional[int]=None
    ) -> tf.data.Dataset:
        """
        Build the production dataset.

        Parameters
        ----------
        data : `DataFrame of shape (input_width + shift, variables)`
            Data to forecast. Input steps need to be inside data.
            It raises an error if not all columns defined in the constructor method are inside data.

        Returns
        -------
        data : `PrefetchDataset of shape (inputs, known, date_inputs, date_labels), labels`
            MapDataset which returns data with shape
            ((inputs, known, date_inputs, date_labels), labels).
        """

        # If `from_dataframe` is used then variables columns from the provided
        # dataframe doesn't need to perfectly match self._data_columns.
        if isinstance(data, pd.DataFrame) and self._data_columns is not None:
            assert data.shape[0] >= self._total_window_size, f"The given dataframe doesn't contain enough values, got {data.shape[0]} values, expected at least {self._total_window_size} values."
            
            if not all(self._data_columns[self.date_columns].isin(data.columns)):
                data, _ = self._date_columns_handler(data)
            
            columns = self._data_columns[self.input_columns + self.label_columns + self.known_columns + self.date_columns]
            assert all(
                columns.isin(data.columns)
            ), f"The given data columns doesn't match the expected columns, got {data.columns}. Expected at least {columns}"
            data = data.loc[:, self._data_columns].values
        else:
            # If an array is provided or a dataframe but `from_dataframe` was not used previously then
            # Data shape has to match the specs saved from the methods `from_array` or `from_dataframe`.
            assert (data.shape[0] >= self._total_window_size and data.shape[1:] == self.data.shape[1:]
            ), f"""The given array doesn't contain enough data, got data of shape {data.shape}.
            Expected at least shape {(self._total_window_size, *self.data.shape[1:])}."""

        data = self._make_dataset(data, batch_size)
        return data

    def get_config(self):
        """Return the config values."""

        return {'input_width': self.input_width,
                'label_width': self.label_width,
                'shift': self.shift,
                'valid_size': self.valid_size,
                'test_size': self.test_size,
                'strategy': self.strategy,
                'batch_size': self.batch_size,
                'preprocessing': self._preprocessing,}

    @property
    def train(self) -> tf.data.Dataset:
        """
        Build the train dataset.

        Returns
        -------
        dataset: `PrefetchDataset of shape (inputs, known, date_inputs, date_labels), labels`
            Train dataset. It cannot be empty.
        """
        return self._make_dataset(self.train_data, self.batch_size)

    @property
    def valid(self) -> tf.data.Dataset:
        """
        Build the valid dataset.

        Returns
        -------
        dataset: `PrefetchDataset of shape (inputs, known, date_inputs, date_labels), labels` or None
            Valid dataset. Return None if valid_data is empty.
        """
        if not np.size(self.valid_data):
            return None
        return self._make_dataset(self.valid_data, self.batch_size)

    @property
    def test(self) -> Union[tf.data.Dataset, None]:
        """
        Build the test dataset.

        Returns`
        -------
        dataset: `PrefetchDataset of shape (i
        nputs, known, date_inputs, date_labels), labels` or None
            Test dataset. Return None if test_data is empty.
        """
        if not np.size(self.test_data):
            return None
        return self._make_dataset(self.test_data, self.batch_size)

    @property
    def train_data(self) -> np.ndarray:
        """
        Return the DataFrame or array associated to the train dataset.

        Raises
        ------
        AssertionError
            It cannot be empty."""
        if self._initialized:
            return self._train_data
        raise AttributeError("""The instance is not initialized.
            Call `from_dataframe` or `from_array` to initialize it.""")

    @property
    def valid_data(self) -> np.ndarray:
        """Return the DataFrame or array associated to the valid dataset.
        It could be an empty DataFrame depending of your parameters."""
        if self._initialized:
            return self._valid_data
        raise AttributeError("""The instance is not initialized.
            Call `from_dataframe` or `from_array` to initialize it.""")

    @property
    def test_data(self) -> np.ndarray:
        """Return the DataFrame or array associated to the test dataset. 
        It could be an empty DataFrame depending of your parameters."""
        if self._initialized:
            return self._test_data
        raise AttributeError("""The instance is not initialized.
            Call `from_dataframe` or `from_array` to initialize it.""")

    @property
    def data(self) -> np.ndarray:
        """Return the original data."""
        if self._initialized:
            return self._data
        raise AttributeError("""The instance is not initialized.
            Call `from_dataframe` or `from_array` to initialize it.""")

    @data.setter
    def data(self, _) -> None:
        """Set the new data."""
        raise AttributeError("You cannot modify `data`, use `from_dataframe` or `from_array` instead.")

    @property
    def input_width(self) -> int:
        """Return the input_width."""
        return self._input_width

    @input_width.setter
    def input_width(self, value) -> None:
        """Return the new input_width."""
        self._input_width = value
        self._compute_window_parameters()
        if self._initialized:
            self._compute_train_valid_test_split()

    @property
    def label_width(self) -> int:
        """Return the label_width."""
        return self._label_width

    @label_width.setter
    def label_width(self, value) -> None:
        """Return the new label_width."""
        self._label_width = value
        self._compute_window_parameters()
        if self._initialized:
            self._compute_train_valid_test_split()

    @property
    def shift(self) -> int:
        """Return the shift."""
        return self._shift

    @shift.setter
    def shift(self, value) -> None:
        """Return the new shift."""
        self._shift = value
        self._compute_window_parameters()
        if self._initialized:
            self._compute_train_valid_test_split()

    @property
    def valid_size(self) -> int:
        """Return the valid_size."""
        return self._valid_size

    @valid_size.setter
    def valid_size(self, value) -> None:
        """Return the new valid_size."""
        self._valid_size = value
        self._compute_window_parameters()
        if self._initialized:
            self._compute_train_valid_test_split()

    @property
    def test_size(self) -> int:
        """Return the test_size."""
        return self._test_size

    @test_size.setter
    def test_size(self, value)-> None:
        """Return the new test_size."""
        self._test_size = value
        self._compute_window_parameters()
        if self._initialized:
            self._compute_train_valid_test_split()

    @property
    def input_columns(self) -> List[Union[int, slice]]:
        """Return the input_width."""
        if self._initialized:
            return self._input_columns
        raise AttributeError("""The instance is not initialized.
            Call `from_dataframe` or `from_array` to initialize it.""")

    @input_columns.setter
    def input_columns(self, _) -> None:
        """Set the new data."""
        raise AttributeError("You cannot modify `input_columns`, use `from_dataframe` or `from_array` instead.")

    @property
    def label_columns(self) -> List[Union[int, slice]]:
        """Return the label_columns."""
        if self._initialized:
            return self._label_columns
        raise AttributeError("""The instance is not initialized.
            Call `from_dataframe` or `from_array` to initialize it.""")

    @label_columns.setter
    def label_columns(self, _) -> None:
        """Set the new data."""
        raise AttributeError("You cannot modify `label_columns`, use `from_dataframe` or `from_array` instead.")

    @property
    def known_columns(self) -> List[Union[int, slice]]:
        """Return the known_columns."""
        if self._initialized:
            return self._known_columns
        raise AttributeError("""The instance is not initialized.
            Call `from_dataframe` or `from_array` to initialize it.""")

    @known_columns.setter
    def known_columns(self, _) -> None:
        """Set the new data."""
        raise AttributeError("You cannot modify `known_columns`, use `from_dataframe` or `from_array` instead.")

    @property
    def date_columns(self) -> List[Union[int, slice]]:
        """Return date_columns."""
        if self._initialized:
            return self._date_columns
        raise AttributeError("""The instance is not initialized.
            Call `from_dataframe` or `from_array` to initialize it.""")

    @date_columns.setter
    def date_columns(self, _) -> None:
        """Set the new data."""
        raise AttributeError("You cannot modify `date_columns`, use `from_dataframe` or `from_array` instead.")

    def _val___init__(self, output: None, *args: list, **kwargs: dict) -> None: # pylint: disable=unused-argument
        """Validates attributes and args of __init__ method."""
        assert (
            self.input_width > 0
        ), f"The input width has to be strictly positive, got {self.input_width}."
        assert (
            self.label_width > 0
        ), f"The label width has to be strictly positive, got {self.label_width}."
        assert (
            self.shift > 0
        ), f"The shift has to be strictly positive, got {self.shift}."
        assert (
            self.label_width < self._total_window_size
        ), f"The label width has to be equal or lower than {self._total_window_size}, got {self.label_width}"
        assert (
            self.test_size >= 0
        ), f"The test size has to be positive or null, got {self.test_size}."
        assert (
            self.valid_size >= 0
        ), f"The valid size has to be positive or null, got {self.valid_size}."
        assert (
            self.strategy in STRATEGIES
        ), f"Invalid strategy, got {self.strategy}, expected one of {STRATEGIES}."
        if self.batch_size:
            assert (
                self.batch_size > 0
            ), f"The batch size has to be strictly positive, got {self.batch_size}."

    def _val__compute_train_valid_test_split(self, output: None, *args: list, **kwargs: dict) -> None: # pylint: disable=unused-argument
        """Validates attributes and args of `_compute_train_valid_test_split` method."""

        assert len(self.label_columns) > 0, "The label columns list is empty."
        assert len(self.input_columns) > 0, "The input columns list is empty."
        assert (
            np.size(self.data)
        ), "The given parameter `data` is an empty DataFrame."

        assert (
            self.input_width + self.shift <= self.data.shape[0]
        ), f"The input width and shift has to be equal or lower than {self.data.shape[0]}, got {self.input_width} and {self.shift}."

        assert np.size(self.train_data), f"""The training dataframe is empty, please redefine the test size or valid size.
                                        Got a test size with {self.test_size} examples and a valid size with {self.valid_size} examples
                                        which lead to a test start at {self._test_start} and a valid start at {self.valid_size}."""

    def _val_from_array(self, output: None, *args: list, **kwargs: dict) -> None: # pylint: disable=unused-argument
        """Validates attributes and args of `_val_from_array` method."""

        assert max(self.input_columns) < self.data.shape[1], f"""Indice {max(self.input_columns)} superior to data shape {self.data.shape}."""
        assert max(self.label_columns) < self.data.shape[1], f"""Indice {max(self.label_columns)} superior to data shape {self.data.shape}."""
        if self.known_columns:
            assert max(self.known_columns) < self.data.shape[1], f"""Indice {max(self.known_columns)} superior to data shape {self.data.shape}."""
        if self.date_columns:
            assert max(self.date_columns) < self.data.shape[1], f"""Indice {max(self.date_columns)} superior to data shape {self.data.shape}."""
        
    def __repr__(self):
        """Display some explanations."""

        if self._initialized:
            example = iter(self.train)
            ((inputs, known, date_inputs, date_labels), labels) = example.get_next()

            return f"""Generator starting... \n

                Input columns are : {self.input_columns}
                Known colulns are : {self.known_columns}
                Labels colulmns are : {self.label_columns}
                date columns are : {self.date_columns} \n

                Parameters remainder:\n
                - input_width : {self.input_width}
                - label_width : {self.label_width}
                - shift : {self.shift}
                - test_size : {self.test_size}
                - valid_size : {self.valid_size}
                - batch_size : {self.batch_size}
                - strategy : {self.strategy} \n

                The train set becomes : \n {self.train_data} \n
                The validation set becomes : \n {self.valid_data} \n
                The test set becomes : \n {self.test_data} \n

                A split example: \n
                    Inputs : \n {inputs}
                    Known inputs : \n {known}
                    Input dates : \n {date_inputs}
                    Label dates : \n {date_labels}
                    Labels : \n {labels}

                    \n Label indices \n {self._label_indices}
                    \n Input indices \n {self._input_indices}
                    """
        else:
            return f"""Generator starting... \n

            Input columns are : {self.input_columns}
            Known colulns are : {self.known_columns}
            Labels colulmns are : {self.label_columns}
            date columns are : {self.date_columns} \n

            Parameters remainder:\n
            - input_width : {self.input_width}
            - label_width : {self.label_width}
            - shift : {self.shift}
            - test_size : {self.test_size}
            - valid_size : {self.valid_size}
            - batch_size : {self.batch_size}
            - strategy : {self.strategy} \n
            
            The generator is not initialized. Call `from_dataframe` or `from_array`."""
